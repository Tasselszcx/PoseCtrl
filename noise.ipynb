{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DDPMScheduler, AutoencoderKL\n",
    "from PIL import Image\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "noise_scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=1000,\n",
    "    beta_start=0.00085,\n",
    "    beta_end=0.012,\n",
    "    beta_schedule=\"scaled_linear\",\n",
    "    clip_sample=False,\n",
    "    steps_offset=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler, AutoencoderKL\n",
    "from PIL import Image\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r'C:\\Users\\31878\\Desktop\\PoseCtrl-main')\n",
    "sys.path.append(r'C:\\Users\\31878\\Desktop\\PoseCtrl-main\\poseCtrl')\n",
    "from poseCtrl.models.pose_adaptor import VPmatrixPoints, ImageProjModel\n",
    "from poseCtrl.models.attention_processor import AttnProcessor, PoseAttnProcessor\n",
    "from poseCtrl.data.dataset import CustomDataset, load_base_points\n",
    "from poseCtrl.models.posectrl import PoseCtrl,PoseCtrlV1\n",
    "import numpy as np\n",
    "\n",
    "vae_model_path = \"stabilityai/sd-vae-ft-mse\"\n",
    "vae = AutoencoderKL.from_pretrained(vae_model_path).to(dtype=torch.float16)\n",
    "base_model_path = r\"C:\\Users\\31878\\Desktop\\model\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    base_model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    scheduler=noise_scheduler,\n",
    "    vae=vae,\n",
    "    feature_extractor=None,\n",
    "    safety_checker=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_sd = pipe.unet.state_dict()\n",
    "attn_procs = {}\n",
    "for name in pipe.unet.attn_processors.keys():\n",
    "        cross_attention_dim = None if name.endswith(\"attn1.processor\") else pipe.unet.config.cross_attention_dim\n",
    "\n",
    "        if name.startswith(\"mid_block\"):\n",
    "            hidden_size = pipe.unet.config.block_out_channels[-1]\n",
    "        elif name.startswith(\"up_blocks\"):\n",
    "            block_id = int(name[len(\"up_blocks.\")])\n",
    "            hidden_size = list(reversed(pipe.unet.config.block_out_channels))[block_id]\n",
    "        elif name.startswith(\"down_blocks\"):\n",
    "            block_id = int(name[len(\"down_blocks.\")])\n",
    "            print(block_id)\n",
    "            hidden_size = pipe.unet.config.block_out_channels[block_id]\n",
    "            # hidden_size = pipe.unet.config.block_in_channels[block_id]\n",
    "            print(hidden_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.unet.down_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copyUnet import *\n",
    "base_model_path = r\"C:\\Users\\31878\\Desktop\\model\"\n",
    "unet=CopyUnetDecoder.from_pretrained(base_model_path, subfolder=\"unet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\31878\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\31878\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copyUnet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CopyUnetDecoder(\n",
       "  (conv_in): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (time_proj): Timesteps()\n",
       "  (time_embedding): TimestepEmbedding(\n",
       "    (linear_1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "    (act): SiLU()\n",
       "    (linear_2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "  )\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): CrossAttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): CrossAttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): CrossAttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): DownBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): UpBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): CrossAttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): CrossAttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): CrossAttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (CopyUp_blocks): ModuleList(\n",
       "    (0): UpBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): CrossAttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): CrossAttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): CrossAttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mid_block): UNetMidBlock2DCrossAttn(\n",
       "    (attentions): ModuleList(\n",
       "      (0): Transformer2DModel(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): ModuleList(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): ModuleList(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): ModuleList(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (resnets): ModuleList(\n",
       "      (0): ResnetBlock2D(\n",
       "        (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "        (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (nonlinearity): SiLU()\n",
       "      )\n",
       "      (1): ResnetBlock2D(\n",
       "        (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "        (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (nonlinearity): SiLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_norm_out): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "  (conv_act): SiLU()\n",
       "  (conv_out): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copyUnet import *\n",
    "\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from accelerate import Accelerator\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import ProjectConfiguration\n",
    "from diffusers import AutoencoderKL, DDPMScheduler, UNet2DConditionModel\n",
    "from transformers import CLIPTextModel, CLIPTokenizer, CLIPVisionModelWithProjection, CLIPProcessor\n",
    "import sys\n",
    "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, StableDiffusionInpaintPipelineLegacy, DDIMScheduler, AutoencoderKL\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "base_model_path = r\"C:\\Users\\31878\\Desktop\\model\"\n",
    "noise_scheduler = DDPMScheduler.from_pretrained(base_model_path, subfolder=\"scheduler\")\n",
    "tokenizer = CLIPTokenizer.from_pretrained(base_model_path, subfolder=\"tokenizer\")\n",
    "text_encoder = CLIPTextModel.from_pretrained(base_model_path, subfolder=\"text_encoder\")\n",
    "vae = AutoencoderKL.from_pretrained(base_model_path, subfolder=\"vae\")\n",
    "# unet = UNet2DConditionModel.from_pretrained(base_model_path, subfolder=\"unet\")\n",
    "# image_encoder = CLIPVisionModelWithProjection.from_pretrained(base_model_path)\n",
    "processor = CLIPProcessor.from_pretrained(\"laion/CLIP-ViT-H-14-laion2B-s32B-b79K\")\n",
    "# freeze parameters of models to save more memory\n",
    "\n",
    "vae.requires_grad_(False)\n",
    "text_encoder.requires_grad_(False)\n",
    "\n",
    "vae.to(device)\n",
    "text_encoder.to(device)\n",
    "\n",
    "unet=CopyUnetDecoder()\n",
    "unet.to(device)\n",
    "unet.requires_grad_(False)\n",
    "unet.CopyUp_blocks.requires_grad_(True)\n",
    "unet.to(device)\n",
    "# image_encoder.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\31878\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\diffusers\\configuration_utils.py:140: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n",
      "  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisy_latents size\n",
      "torch.Size([4, 4, 64, 64])\n",
      "timesteps size\n",
      "torch.Size([4])\n",
      "encoder_hidden_states size\n",
      "torch.Size([4, 77, 768])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m\n\u001b[0;32m      6\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[0;32m      7\u001b[0m     train_dataset,\n\u001b[0;32m      8\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      9\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m     10\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m---> 13\u001b[0m     latents \u001b[38;5;241m=\u001b[39m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlatent_dist\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m     14\u001b[0m     latents \u001b[38;5;241m=\u001b[39m latents \u001b[38;5;241m*\u001b[39m vae\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mscaling_factor\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Sample noise that we'll add to the latents\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\diffusers\\utils\\accelerate_utils.py:46\u001b[0m, in \u001b[0;36mapply_forward_hook.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_hf_hook\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hf_hook, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre_forward\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpre_forward(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\diffusers\\models\\autoencoders\\autoencoder_kl.py:281\u001b[0m, in \u001b[0;36mAutoencoderKL.encode\u001b[1;34m(self, x, return_dict)\u001b[0m\n\u001b[0;32m    279\u001b[0m     h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(encoded_slices)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 281\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m posterior \u001b[38;5;241m=\u001b[39m DiagonalGaussianDistribution(h)\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\diffusers\\models\\autoencoders\\autoencoder_kl.py:255\u001b[0m, in \u001b[0;36mAutoencoderKL._encode\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_tiling \u001b[38;5;129;01mand\u001b[39;00m (width \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtile_sample_min_size \u001b[38;5;129;01mor\u001b[39;00m height \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtile_sample_min_size):\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tiled_encode(x)\n\u001b[1;32m--> 255\u001b[0m enc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_conv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     enc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_conv(enc)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\diffusers\\models\\autoencoders\\vae.py:172\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, sample)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;66;03m# down\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m down_block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_blocks:\n\u001b[1;32m--> 172\u001b[0m         sample \u001b[38;5;241m=\u001b[39m \u001b[43mdown_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# middle\u001b[39;00m\n\u001b[0;32m    175\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmid_block(sample)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\diffusers\\models\\unets\\unet_2d_blocks.py:1474\u001b[0m, in \u001b[0;36mDownEncoderBlock2D.forward\u001b[1;34m(self, hidden_states, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1471\u001b[0m     deprecate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m, deprecation_message)\n\u001b[0;32m   1473\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m resnet \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresnets:\n\u001b[1;32m-> 1474\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsamplers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1477\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m downsampler \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsamplers:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\diffusers\\models\\resnet.py:366\u001b[0m, in \u001b[0;36mResnetBlock2D.forward\u001b[1;34m(self, input_tensor, temb, *args, **kwargs)\u001b[0m\n\u001b[0;32m    363\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnonlinearity(hidden_states)\n\u001b[0;32m    365\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m--> 366\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_shortcut \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     input_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_shortcut(input_tensor)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from poseCtrl.data.dataset import CustomDataset, load_base_points\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "train_dataset = CustomDataset(r'C:\\Users\\31878\\Desktop\\pic')\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=4,\n",
    "    num_workers=0,\n",
    ")\n",
    "for step, batch in enumerate(train_dataloader):\n",
    "    latents = vae.encode(batch[\"image\"].to(device)).latent_dist.sample()\n",
    "    latents = latents * vae.config.scaling_factor\n",
    "\n",
    "    # Sample noise that we'll add to the latents\n",
    "    noise = torch.randn_like(latents)\n",
    "    bsz = latents.shape[0]\n",
    "    # Sample a random timestep for each image\n",
    "    timesteps = torch.randint(0, noise_scheduler.num_train_timesteps, (bsz,), device=latents.device)\n",
    "    min_step = 10\n",
    "    timesteps = timesteps.long()\n",
    "\n",
    "    # Add noise to the latents according to the noise magnitude at each timestep\n",
    "    # (this is the forward diffusion process)\n",
    "    noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
    "\n",
    "    text_input_ids = tokenizer(\n",
    "            \"girl\",\n",
    "            max_length=tokenizer.model_max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).input_ids.to(device) \n",
    "    encoder_hidden_states = text_encoder(text_input_ids)[0]\n",
    "    encoder_hidden_states = encoder_hidden_states.repeat(4, 1, 1) \n",
    "\n",
    "    print(\"noisy_latents size\")\n",
    "    print(noisy_latents.size())\n",
    "    print(\"timesteps size\")\n",
    "    print(timesteps.size())\n",
    "    print(\"encoder_hidden_states size\")\n",
    "    print(encoder_hidden_states.size())\n",
    "\n",
    "    # noise_pred = unet(noisy_latents, timesteps, encoder_hidden_states=encoder_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisy_latents size: torch.Size([4, 4, 64, 64])\n",
      "timesteps size: torch.Size([4])\n",
      "encoder_hidden_states size: torch.Size([4, 77, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#  noisy_latents \n",
    "noisy_latents = torch.randn(4, 4, 64, 64).to(device)\n",
    "\n",
    "#  timesteps \n",
    "timesteps = torch.randint(0, 1000, (4,)).to(device)\n",
    "\n",
    "#  encoder_hidden_states \n",
    "encoder_hidden_states = torch.randn(4, 77, 768).to(device)\n",
    "\n",
    "# \n",
    "print(\"noisy_latents size:\", noisy_latents.size())\n",
    "print(\"timesteps size:\", timesteps.size())\n",
    "print(\"encoder_hidden_states size:\", encoder_hidden_states.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 320, 64, 64])\n",
      "execute\n",
      "sample.size\n",
      "torch.Size([4, 320, 64, 64])\n",
      "copySample.size\n",
      "torch.Size([4, 320, 64, 64])\n",
      "lerpAlphaTest\n"
     ]
    }
   ],
   "source": [
    "noise_pred = unet(noisy_latents, timesteps, encoder_hidden_states=encoder_hidden_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ori_unet = UNet2DConditionModel.from_pretrained(base_model_path, subfolder=\"unet\")\n",
    "Ori_unet.to(device)\n",
    "Ori_noise_pred= Ori_unet(noisy_latents, timesteps, encoder_hidden_states=encoder_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Ori_unet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Num Elements: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;241m.\u001b[39mnumel()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m total_params\n\u001b[1;32m----> 9\u001b[0m total_params \u001b[38;5;241m=\u001b[39m count_parameters(\u001b[43mOri_unet\u001b[49m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal trainable parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Ori_unet' is not defined"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    total_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            total_params += param.numel()\n",
    "            print(f\"Parameter: {name}, Size: {param.size()}, Num Elements: {param.numel()}\")\n",
    "    return total_params\n",
    "\n",
    "total_params = count_parameters(Ori_unet)\n",
    "print(f\"Total trainable parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: CopyUp_blocks.0.resnets.0.norm1.weight, Size: torch.Size([2560]), Num Elements: 2560\n",
      "Parameter: CopyUp_blocks.0.resnets.0.norm1.bias, Size: torch.Size([2560]), Num Elements: 2560\n",
      "Parameter: CopyUp_blocks.0.resnets.0.conv1.weight, Size: torch.Size([1280, 2560, 3, 3]), Num Elements: 29491200\n",
      "Parameter: CopyUp_blocks.0.resnets.0.conv1.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.0.resnets.0.time_emb_proj.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.0.resnets.0.time_emb_proj.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.0.resnets.0.norm2.weight, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.0.resnets.0.norm2.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.0.resnets.0.conv2.weight, Size: torch.Size([1280, 1280, 3, 3]), Num Elements: 14745600\n",
      "Parameter: CopyUp_blocks.0.resnets.0.conv2.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.0.resnets.0.conv_shortcut.weight, Size: torch.Size([1280, 2560, 1, 1]), Num Elements: 3276800\n",
      "Parameter: CopyUp_blocks.0.resnets.0.conv_shortcut.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.0.resnets.1.norm1.weight, Size: torch.Size([2560]), Num Elements: 2560\n",
      "Parameter: CopyUp_blocks.0.resnets.1.norm1.bias, Size: torch.Size([2560]), Num Elements: 2560\n",
      "Parameter: CopyUp_blocks.0.resnets.1.conv1.weight, Size: torch.Size([1280, 2560, 3, 3]), Num Elements: 29491200\n",
      "Parameter: CopyUp_blocks.0.resnets.1.conv1.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.0.resnets.1.time_emb_proj.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.0.resnets.1.time_emb_proj.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.0.resnets.1.norm2.weight, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.0.resnets.1.norm2.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.0.resnets.1.conv2.weight, Size: torch.Size([1280, 1280, 3, 3]), Num Elements: 14745600\n",
      "Parameter: CopyUp_blocks.0.resnets.1.conv2.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.0.resnets.1.conv_shortcut.weight, Size: torch.Size([1280, 2560, 1, 1]), Num Elements: 3276800\n",
      "Parameter: CopyUp_blocks.0.resnets.1.conv_shortcut.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.0.resnets.2.norm1.weight, Size: torch.Size([2560]), Num Elements: 2560\n",
      "Parameter: CopyUp_blocks.0.resnets.2.norm1.bias, Size: torch.Size([2560]), Num Elements: 2560\n",
      "Parameter: CopyUp_blocks.0.resnets.2.conv1.weight, Size: torch.Size([1280, 2560, 3, 3]), Num Elements: 29491200\n",
      "Parameter: CopyUp_blocks.0.resnets.2.conv1.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.0.resnets.2.time_emb_proj.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.0.resnets.2.time_emb_proj.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.0.resnets.2.norm2.weight, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.0.resnets.2.norm2.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.0.resnets.2.conv2.weight, Size: torch.Size([1280, 1280, 3, 3]), Num Elements: 14745600\n",
      "Parameter: CopyUp_blocks.0.resnets.2.conv2.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.0.resnets.2.conv_shortcut.weight, Size: torch.Size([1280, 2560, 1, 1]), Num Elements: 3276800\n",
      "Parameter: CopyUp_blocks.0.resnets.2.conv_shortcut.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.0.upsamplers.0.conv.weight, Size: torch.Size([1280, 1280, 3, 3]), Num Elements: 14745600\n",
      "Parameter: CopyUp_blocks.0.upsamplers.0.conv.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.0.norm.weight, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.0.norm.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.0.proj_in.weight, Size: torch.Size([1280, 1280, 1, 1]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.0.proj_in.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.0.transformer_blocks.0.norm1.weight, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.0.transformer_blocks.0.norm1.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.0.transformer_blocks.0.norm2.weight, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.0.transformer_blocks.0.norm2.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight, Size: torch.Size([1280, 768]), Num Elements: 983040\n",
      "Parameter: CopyUp_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight, Size: torch.Size([1280, 768]), Num Elements: 983040\n",
      "Parameter: CopyUp_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.0.transformer_blocks.0.norm3.weight, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.0.transformer_blocks.0.norm3.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight, Size: torch.Size([10240, 1280]), Num Elements: 13107200\n",
      "Parameter: CopyUp_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias, Size: torch.Size([10240]), Num Elements: 10240\n",
      "Parameter: CopyUp_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight, Size: torch.Size([1280, 5120]), Num Elements: 6553600\n",
      "Parameter: CopyUp_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.0.proj_out.weight, Size: torch.Size([1280, 1280, 1, 1]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.0.proj_out.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.1.norm.weight, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.1.norm.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.1.proj_in.weight, Size: torch.Size([1280, 1280, 1, 1]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.1.proj_in.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.1.transformer_blocks.0.norm1.weight, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.1.transformer_blocks.0.norm1.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.1.transformer_blocks.0.norm2.weight, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.1.transformer_blocks.0.norm2.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight, Size: torch.Size([1280, 768]), Num Elements: 983040\n",
      "Parameter: CopyUp_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight, Size: torch.Size([1280, 768]), Num Elements: 983040\n",
      "Parameter: CopyUp_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.1.transformer_blocks.0.norm3.weight, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.1.transformer_blocks.0.norm3.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight, Size: torch.Size([10240, 1280]), Num Elements: 13107200\n",
      "Parameter: CopyUp_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias, Size: torch.Size([10240]), Num Elements: 10240\n",
      "Parameter: CopyUp_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight, Size: torch.Size([1280, 5120]), Num Elements: 6553600\n",
      "Parameter: CopyUp_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.1.proj_out.weight, Size: torch.Size([1280, 1280, 1, 1]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.1.proj_out.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.2.norm.weight, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.2.norm.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.2.proj_in.weight, Size: torch.Size([1280, 1280, 1, 1]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.2.proj_in.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.2.transformer_blocks.0.norm1.weight, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.2.transformer_blocks.0.norm1.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.2.transformer_blocks.0.attn1.to_q.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.2.transformer_blocks.0.attn1.to_k.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.2.transformer_blocks.0.attn1.to_v.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.2.transformer_blocks.0.norm2.weight, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.2.transformer_blocks.0.norm2.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.2.transformer_blocks.0.attn2.to_q.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.2.transformer_blocks.0.attn2.to_k.weight, Size: torch.Size([1280, 768]), Num Elements: 983040\n",
      "Parameter: CopyUp_blocks.1.attentions.2.transformer_blocks.0.attn2.to_v.weight, Size: torch.Size([1280, 768]), Num Elements: 983040\n",
      "Parameter: CopyUp_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.2.transformer_blocks.0.norm3.weight, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.2.transformer_blocks.0.norm3.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.weight, Size: torch.Size([10240, 1280]), Num Elements: 13107200\n",
      "Parameter: CopyUp_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.bias, Size: torch.Size([10240]), Num Elements: 10240\n",
      "Parameter: CopyUp_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.weight, Size: torch.Size([1280, 5120]), Num Elements: 6553600\n",
      "Parameter: CopyUp_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.attentions.2.proj_out.weight, Size: torch.Size([1280, 1280, 1, 1]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.attentions.2.proj_out.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.resnets.0.norm1.weight, Size: torch.Size([2560]), Num Elements: 2560\n",
      "Parameter: CopyUp_blocks.1.resnets.0.norm1.bias, Size: torch.Size([2560]), Num Elements: 2560\n",
      "Parameter: CopyUp_blocks.1.resnets.0.conv1.weight, Size: torch.Size([1280, 2560, 3, 3]), Num Elements: 29491200\n",
      "Parameter: CopyUp_blocks.1.resnets.0.conv1.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.resnets.0.time_emb_proj.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.resnets.0.time_emb_proj.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.resnets.0.norm2.weight, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.resnets.0.norm2.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.resnets.0.conv2.weight, Size: torch.Size([1280, 1280, 3, 3]), Num Elements: 14745600\n",
      "Parameter: CopyUp_blocks.1.resnets.0.conv2.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.resnets.0.conv_shortcut.weight, Size: torch.Size([1280, 2560, 1, 1]), Num Elements: 3276800\n",
      "Parameter: CopyUp_blocks.1.resnets.0.conv_shortcut.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.resnets.1.norm1.weight, Size: torch.Size([2560]), Num Elements: 2560\n",
      "Parameter: CopyUp_blocks.1.resnets.1.norm1.bias, Size: torch.Size([2560]), Num Elements: 2560\n",
      "Parameter: CopyUp_blocks.1.resnets.1.conv1.weight, Size: torch.Size([1280, 2560, 3, 3]), Num Elements: 29491200\n",
      "Parameter: CopyUp_blocks.1.resnets.1.conv1.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.resnets.1.time_emb_proj.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.resnets.1.time_emb_proj.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.resnets.1.norm2.weight, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.resnets.1.norm2.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.resnets.1.conv2.weight, Size: torch.Size([1280, 1280, 3, 3]), Num Elements: 14745600\n",
      "Parameter: CopyUp_blocks.1.resnets.1.conv2.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.resnets.1.conv_shortcut.weight, Size: torch.Size([1280, 2560, 1, 1]), Num Elements: 3276800\n",
      "Parameter: CopyUp_blocks.1.resnets.1.conv_shortcut.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.resnets.2.norm1.weight, Size: torch.Size([1920]), Num Elements: 1920\n",
      "Parameter: CopyUp_blocks.1.resnets.2.norm1.bias, Size: torch.Size([1920]), Num Elements: 1920\n",
      "Parameter: CopyUp_blocks.1.resnets.2.conv1.weight, Size: torch.Size([1280, 1920, 3, 3]), Num Elements: 22118400\n",
      "Parameter: CopyUp_blocks.1.resnets.2.conv1.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.resnets.2.time_emb_proj.weight, Size: torch.Size([1280, 1280]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.1.resnets.2.time_emb_proj.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.resnets.2.norm2.weight, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.resnets.2.norm2.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.resnets.2.conv2.weight, Size: torch.Size([1280, 1280, 3, 3]), Num Elements: 14745600\n",
      "Parameter: CopyUp_blocks.1.resnets.2.conv2.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.resnets.2.conv_shortcut.weight, Size: torch.Size([1280, 1920, 1, 1]), Num Elements: 2457600\n",
      "Parameter: CopyUp_blocks.1.resnets.2.conv_shortcut.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.1.upsamplers.0.conv.weight, Size: torch.Size([1280, 1280, 3, 3]), Num Elements: 14745600\n",
      "Parameter: CopyUp_blocks.1.upsamplers.0.conv.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.2.attentions.0.norm.weight, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.0.norm.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.0.proj_in.weight, Size: torch.Size([640, 640, 1, 1]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.0.proj_in.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.0.transformer_blocks.0.norm1.weight, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.0.transformer_blocks.0.norm1.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight, Size: torch.Size([640, 640]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight, Size: torch.Size([640, 640]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight, Size: torch.Size([640, 640]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight, Size: torch.Size([640, 640]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.0.transformer_blocks.0.norm2.weight, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.0.transformer_blocks.0.norm2.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight, Size: torch.Size([640, 640]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight, Size: torch.Size([640, 768]), Num Elements: 491520\n",
      "Parameter: CopyUp_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight, Size: torch.Size([640, 768]), Num Elements: 491520\n",
      "Parameter: CopyUp_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight, Size: torch.Size([640, 640]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.0.transformer_blocks.0.norm3.weight, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.0.transformer_blocks.0.norm3.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight, Size: torch.Size([5120, 640]), Num Elements: 3276800\n",
      "Parameter: CopyUp_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias, Size: torch.Size([5120]), Num Elements: 5120\n",
      "Parameter: CopyUp_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight, Size: torch.Size([640, 2560]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.0.proj_out.weight, Size: torch.Size([640, 640, 1, 1]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.0.proj_out.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.1.norm.weight, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.1.norm.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.1.proj_in.weight, Size: torch.Size([640, 640, 1, 1]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.1.proj_in.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.1.transformer_blocks.0.norm1.weight, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.1.transformer_blocks.0.norm1.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight, Size: torch.Size([640, 640]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight, Size: torch.Size([640, 640]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight, Size: torch.Size([640, 640]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight, Size: torch.Size([640, 640]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.1.transformer_blocks.0.norm2.weight, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.1.transformer_blocks.0.norm2.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight, Size: torch.Size([640, 640]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight, Size: torch.Size([640, 768]), Num Elements: 491520\n",
      "Parameter: CopyUp_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight, Size: torch.Size([640, 768]), Num Elements: 491520\n",
      "Parameter: CopyUp_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight, Size: torch.Size([640, 640]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.1.transformer_blocks.0.norm3.weight, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.1.transformer_blocks.0.norm3.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight, Size: torch.Size([5120, 640]), Num Elements: 3276800\n",
      "Parameter: CopyUp_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias, Size: torch.Size([5120]), Num Elements: 5120\n",
      "Parameter: CopyUp_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight, Size: torch.Size([640, 2560]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.1.proj_out.weight, Size: torch.Size([640, 640, 1, 1]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.1.proj_out.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.2.norm.weight, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.2.norm.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.2.proj_in.weight, Size: torch.Size([640, 640, 1, 1]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.2.proj_in.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.2.transformer_blocks.0.norm1.weight, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.2.transformer_blocks.0.norm1.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.2.transformer_blocks.0.attn1.to_q.weight, Size: torch.Size([640, 640]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.2.transformer_blocks.0.attn1.to_k.weight, Size: torch.Size([640, 640]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.2.transformer_blocks.0.attn1.to_v.weight, Size: torch.Size([640, 640]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.2.transformer_blocks.0.attn1.to_out.0.weight, Size: torch.Size([640, 640]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.2.transformer_blocks.0.attn1.to_out.0.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.2.transformer_blocks.0.norm2.weight, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.2.transformer_blocks.0.norm2.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.2.transformer_blocks.0.attn2.to_q.weight, Size: torch.Size([640, 640]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.2.transformer_blocks.0.attn2.to_k.weight, Size: torch.Size([640, 768]), Num Elements: 491520\n",
      "Parameter: CopyUp_blocks.2.attentions.2.transformer_blocks.0.attn2.to_v.weight, Size: torch.Size([640, 768]), Num Elements: 491520\n",
      "Parameter: CopyUp_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0.weight, Size: torch.Size([640, 640]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.2.transformer_blocks.0.norm3.weight, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.2.transformer_blocks.0.norm3.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.2.transformer_blocks.0.ff.net.0.proj.weight, Size: torch.Size([5120, 640]), Num Elements: 3276800\n",
      "Parameter: CopyUp_blocks.2.attentions.2.transformer_blocks.0.ff.net.0.proj.bias, Size: torch.Size([5120]), Num Elements: 5120\n",
      "Parameter: CopyUp_blocks.2.attentions.2.transformer_blocks.0.ff.net.2.weight, Size: torch.Size([640, 2560]), Num Elements: 1638400\n",
      "Parameter: CopyUp_blocks.2.attentions.2.transformer_blocks.0.ff.net.2.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.attentions.2.proj_out.weight, Size: torch.Size([640, 640, 1, 1]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.2.attentions.2.proj_out.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.resnets.0.norm1.weight, Size: torch.Size([1920]), Num Elements: 1920\n",
      "Parameter: CopyUp_blocks.2.resnets.0.norm1.bias, Size: torch.Size([1920]), Num Elements: 1920\n",
      "Parameter: CopyUp_blocks.2.resnets.0.conv1.weight, Size: torch.Size([640, 1920, 3, 3]), Num Elements: 11059200\n",
      "Parameter: CopyUp_blocks.2.resnets.0.conv1.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.resnets.0.time_emb_proj.weight, Size: torch.Size([640, 1280]), Num Elements: 819200\n",
      "Parameter: CopyUp_blocks.2.resnets.0.time_emb_proj.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.resnets.0.norm2.weight, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.resnets.0.norm2.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.resnets.0.conv2.weight, Size: torch.Size([640, 640, 3, 3]), Num Elements: 3686400\n",
      "Parameter: CopyUp_blocks.2.resnets.0.conv2.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.resnets.0.conv_shortcut.weight, Size: torch.Size([640, 1920, 1, 1]), Num Elements: 1228800\n",
      "Parameter: CopyUp_blocks.2.resnets.0.conv_shortcut.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.resnets.1.norm1.weight, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.2.resnets.1.norm1.bias, Size: torch.Size([1280]), Num Elements: 1280\n",
      "Parameter: CopyUp_blocks.2.resnets.1.conv1.weight, Size: torch.Size([640, 1280, 3, 3]), Num Elements: 7372800\n",
      "Parameter: CopyUp_blocks.2.resnets.1.conv1.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.resnets.1.time_emb_proj.weight, Size: torch.Size([640, 1280]), Num Elements: 819200\n",
      "Parameter: CopyUp_blocks.2.resnets.1.time_emb_proj.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.resnets.1.norm2.weight, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.resnets.1.norm2.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.resnets.1.conv2.weight, Size: torch.Size([640, 640, 3, 3]), Num Elements: 3686400\n",
      "Parameter: CopyUp_blocks.2.resnets.1.conv2.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.resnets.1.conv_shortcut.weight, Size: torch.Size([640, 1280, 1, 1]), Num Elements: 819200\n",
      "Parameter: CopyUp_blocks.2.resnets.1.conv_shortcut.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.resnets.2.norm1.weight, Size: torch.Size([960]), Num Elements: 960\n",
      "Parameter: CopyUp_blocks.2.resnets.2.norm1.bias, Size: torch.Size([960]), Num Elements: 960\n",
      "Parameter: CopyUp_blocks.2.resnets.2.conv1.weight, Size: torch.Size([640, 960, 3, 3]), Num Elements: 5529600\n",
      "Parameter: CopyUp_blocks.2.resnets.2.conv1.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.resnets.2.time_emb_proj.weight, Size: torch.Size([640, 1280]), Num Elements: 819200\n",
      "Parameter: CopyUp_blocks.2.resnets.2.time_emb_proj.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.resnets.2.norm2.weight, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.resnets.2.norm2.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.resnets.2.conv2.weight, Size: torch.Size([640, 640, 3, 3]), Num Elements: 3686400\n",
      "Parameter: CopyUp_blocks.2.resnets.2.conv2.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.resnets.2.conv_shortcut.weight, Size: torch.Size([640, 960, 1, 1]), Num Elements: 614400\n",
      "Parameter: CopyUp_blocks.2.resnets.2.conv_shortcut.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.2.upsamplers.0.conv.weight, Size: torch.Size([640, 640, 3, 3]), Num Elements: 3686400\n",
      "Parameter: CopyUp_blocks.2.upsamplers.0.conv.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.3.attentions.0.norm.weight, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.0.norm.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.0.proj_in.weight, Size: torch.Size([320, 320, 1, 1]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.0.proj_in.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.0.transformer_blocks.0.norm1.weight, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.0.transformer_blocks.0.norm1.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.0.transformer_blocks.0.attn1.to_q.weight, Size: torch.Size([320, 320]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.0.transformer_blocks.0.attn1.to_k.weight, Size: torch.Size([320, 320]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.0.transformer_blocks.0.attn1.to_v.weight, Size: torch.Size([320, 320]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.0.transformer_blocks.0.attn1.to_out.0.weight, Size: torch.Size([320, 320]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.0.transformer_blocks.0.attn1.to_out.0.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.0.transformer_blocks.0.norm2.weight, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.0.transformer_blocks.0.norm2.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.0.transformer_blocks.0.attn2.to_q.weight, Size: torch.Size([320, 320]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.0.transformer_blocks.0.attn2.to_k.weight, Size: torch.Size([320, 768]), Num Elements: 245760\n",
      "Parameter: CopyUp_blocks.3.attentions.0.transformer_blocks.0.attn2.to_v.weight, Size: torch.Size([320, 768]), Num Elements: 245760\n",
      "Parameter: CopyUp_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0.weight, Size: torch.Size([320, 320]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.0.transformer_blocks.0.norm3.weight, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.0.transformer_blocks.0.norm3.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.0.transformer_blocks.0.ff.net.0.proj.weight, Size: torch.Size([2560, 320]), Num Elements: 819200\n",
      "Parameter: CopyUp_blocks.3.attentions.0.transformer_blocks.0.ff.net.0.proj.bias, Size: torch.Size([2560]), Num Elements: 2560\n",
      "Parameter: CopyUp_blocks.3.attentions.0.transformer_blocks.0.ff.net.2.weight, Size: torch.Size([320, 1280]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.3.attentions.0.transformer_blocks.0.ff.net.2.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.0.proj_out.weight, Size: torch.Size([320, 320, 1, 1]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.0.proj_out.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.1.norm.weight, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.1.norm.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.1.proj_in.weight, Size: torch.Size([320, 320, 1, 1]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.1.proj_in.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.1.transformer_blocks.0.norm1.weight, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.1.transformer_blocks.0.norm1.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.1.transformer_blocks.0.attn1.to_q.weight, Size: torch.Size([320, 320]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.1.transformer_blocks.0.attn1.to_k.weight, Size: torch.Size([320, 320]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.1.transformer_blocks.0.attn1.to_v.weight, Size: torch.Size([320, 320]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.1.transformer_blocks.0.attn1.to_out.0.weight, Size: torch.Size([320, 320]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.1.transformer_blocks.0.attn1.to_out.0.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.1.transformer_blocks.0.norm2.weight, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.1.transformer_blocks.0.norm2.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.1.transformer_blocks.0.attn2.to_q.weight, Size: torch.Size([320, 320]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.1.transformer_blocks.0.attn2.to_k.weight, Size: torch.Size([320, 768]), Num Elements: 245760\n",
      "Parameter: CopyUp_blocks.3.attentions.1.transformer_blocks.0.attn2.to_v.weight, Size: torch.Size([320, 768]), Num Elements: 245760\n",
      "Parameter: CopyUp_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0.weight, Size: torch.Size([320, 320]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.1.transformer_blocks.0.norm3.weight, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.1.transformer_blocks.0.norm3.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.1.transformer_blocks.0.ff.net.0.proj.weight, Size: torch.Size([2560, 320]), Num Elements: 819200\n",
      "Parameter: CopyUp_blocks.3.attentions.1.transformer_blocks.0.ff.net.0.proj.bias, Size: torch.Size([2560]), Num Elements: 2560\n",
      "Parameter: CopyUp_blocks.3.attentions.1.transformer_blocks.0.ff.net.2.weight, Size: torch.Size([320, 1280]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.3.attentions.1.transformer_blocks.0.ff.net.2.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.1.proj_out.weight, Size: torch.Size([320, 320, 1, 1]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.1.proj_out.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.2.norm.weight, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.2.norm.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.2.proj_in.weight, Size: torch.Size([320, 320, 1, 1]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.2.proj_in.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.2.transformer_blocks.0.norm1.weight, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.2.transformer_blocks.0.norm1.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.2.transformer_blocks.0.attn1.to_q.weight, Size: torch.Size([320, 320]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.2.transformer_blocks.0.attn1.to_k.weight, Size: torch.Size([320, 320]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.2.transformer_blocks.0.attn1.to_v.weight, Size: torch.Size([320, 320]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.2.transformer_blocks.0.attn1.to_out.0.weight, Size: torch.Size([320, 320]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.2.transformer_blocks.0.attn1.to_out.0.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.2.transformer_blocks.0.norm2.weight, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.2.transformer_blocks.0.norm2.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.2.transformer_blocks.0.attn2.to_q.weight, Size: torch.Size([320, 320]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.2.transformer_blocks.0.attn2.to_k.weight, Size: torch.Size([320, 768]), Num Elements: 245760\n",
      "Parameter: CopyUp_blocks.3.attentions.2.transformer_blocks.0.attn2.to_v.weight, Size: torch.Size([320, 768]), Num Elements: 245760\n",
      "Parameter: CopyUp_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0.weight, Size: torch.Size([320, 320]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.2.transformer_blocks.0.norm3.weight, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.2.transformer_blocks.0.norm3.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.2.transformer_blocks.0.ff.net.0.proj.weight, Size: torch.Size([2560, 320]), Num Elements: 819200\n",
      "Parameter: CopyUp_blocks.3.attentions.2.transformer_blocks.0.ff.net.0.proj.bias, Size: torch.Size([2560]), Num Elements: 2560\n",
      "Parameter: CopyUp_blocks.3.attentions.2.transformer_blocks.0.ff.net.2.weight, Size: torch.Size([320, 1280]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.3.attentions.2.transformer_blocks.0.ff.net.2.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.attentions.2.proj_out.weight, Size: torch.Size([320, 320, 1, 1]), Num Elements: 102400\n",
      "Parameter: CopyUp_blocks.3.attentions.2.proj_out.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.resnets.0.norm1.weight, Size: torch.Size([960]), Num Elements: 960\n",
      "Parameter: CopyUp_blocks.3.resnets.0.norm1.bias, Size: torch.Size([960]), Num Elements: 960\n",
      "Parameter: CopyUp_blocks.3.resnets.0.conv1.weight, Size: torch.Size([320, 960, 3, 3]), Num Elements: 2764800\n",
      "Parameter: CopyUp_blocks.3.resnets.0.conv1.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.resnets.0.time_emb_proj.weight, Size: torch.Size([320, 1280]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.3.resnets.0.time_emb_proj.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.resnets.0.norm2.weight, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.resnets.0.norm2.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.resnets.0.conv2.weight, Size: torch.Size([320, 320, 3, 3]), Num Elements: 921600\n",
      "Parameter: CopyUp_blocks.3.resnets.0.conv2.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.resnets.0.conv_shortcut.weight, Size: torch.Size([320, 960, 1, 1]), Num Elements: 307200\n",
      "Parameter: CopyUp_blocks.3.resnets.0.conv_shortcut.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.resnets.1.norm1.weight, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.3.resnets.1.norm1.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.3.resnets.1.conv1.weight, Size: torch.Size([320, 640, 3, 3]), Num Elements: 1843200\n",
      "Parameter: CopyUp_blocks.3.resnets.1.conv1.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.resnets.1.time_emb_proj.weight, Size: torch.Size([320, 1280]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.3.resnets.1.time_emb_proj.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.resnets.1.norm2.weight, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.resnets.1.norm2.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.resnets.1.conv2.weight, Size: torch.Size([320, 320, 3, 3]), Num Elements: 921600\n",
      "Parameter: CopyUp_blocks.3.resnets.1.conv2.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.resnets.1.conv_shortcut.weight, Size: torch.Size([320, 640, 1, 1]), Num Elements: 204800\n",
      "Parameter: CopyUp_blocks.3.resnets.1.conv_shortcut.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.resnets.2.norm1.weight, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.3.resnets.2.norm1.bias, Size: torch.Size([640]), Num Elements: 640\n",
      "Parameter: CopyUp_blocks.3.resnets.2.conv1.weight, Size: torch.Size([320, 640, 3, 3]), Num Elements: 1843200\n",
      "Parameter: CopyUp_blocks.3.resnets.2.conv1.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.resnets.2.time_emb_proj.weight, Size: torch.Size([320, 1280]), Num Elements: 409600\n",
      "Parameter: CopyUp_blocks.3.resnets.2.time_emb_proj.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.resnets.2.norm2.weight, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.resnets.2.norm2.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.resnets.2.conv2.weight, Size: torch.Size([320, 320, 3, 3]), Num Elements: 921600\n",
      "Parameter: CopyUp_blocks.3.resnets.2.conv2.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Parameter: CopyUp_blocks.3.resnets.2.conv_shortcut.weight, Size: torch.Size([320, 640, 1, 1]), Num Elements: 204800\n",
      "Parameter: CopyUp_blocks.3.resnets.2.conv_shortcut.bias, Size: torch.Size([320]), Num Elements: 320\n",
      "Total trainable parameters: 510795840\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    total_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            total_params += param.numel()\n",
    "            print(f\"Parameter: {name}, Size: {param.size()}, Num Elements: {param.numel()}\")\n",
    "    return total_params\n",
    "\n",
    "total_params = count_parameters(unet)\n",
    "print(f\"Total trainable parameters: {total_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
